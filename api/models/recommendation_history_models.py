#!/usr/bin/env python3
"""
Recommendation History Storage Models
====================================

Database models for storing historical trading recommendations generated by cron jobs.
Provides comprehensive tracking of all recommendations for analysis, backtesting, and performance evaluation.
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from enum import Enum
from dataclasses import dataclass, asdict
from pathlib import Path
import uuid

import motor.motor_asyncio
from pymongo import MongoClient, ASCENDING, DESCENDING
from bson import ObjectId
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)

class RecommendationSource(Enum):
    """Source of recommendation generation."""
    CRON_SCHEDULED = "cron_scheduled"
    API_REQUEST = "api_request"
    MANUAL_TRIGGER = "manual_trigger"
    BACKTEST = "backtest"

class RecommendationStrategy(Enum):
    """Trading strategy types."""
    SHORTTERM = "shortterm"
    SWING = "swing"
    LONGTERM = "longterm"
    INTRADAY = "intraday"
    PORTFOLIO = "portfolio"

class RecommendationAction(Enum):
    """Recommendation actions."""
    BUY = "buy"
    SELL = "sell"
    HOLD = "hold"
    STRONG_BUY = "strong_buy"
    MODERATE_BUY = "moderate_buy"
    AVOID = "avoid"

@dataclass
class HistoricalRecommendationMetadata:
    """Metadata for historical recommendations."""
    execution_id: str  # Links to cron execution
    cron_job_id: str
    algorithm_version: str
    market_condition: str
    trading_session: str
    api_response_time_ms: float
    total_stocks_analyzed: int
    filter_criteria_used: Dict[str, Any]
    scoring_methodology: Dict[str, Any]
    data_sources: List[str]
    confidence_threshold: float
    timestamp: datetime
    server_info: Dict[str, Any]

class HistoricalStockRecommendation(BaseModel):
    """Individual historical stock recommendation with enhanced tracking."""
    
    # Basic stock information
    symbol: str = Field(..., description="Stock symbol")
    name: str = Field(..., description="Company name")
    exchange: str = Field(default="NSE", description="Stock exchange")
    sector: Optional[str] = Field(None, description="Industry sector")
    
    # Price and performance data
    price_at_recommendation: float = Field(..., description="Stock price when recommended")
    current_price: Optional[float] = Field(None, description="Current price (if available)")
    target_price: Optional[float] = Field(None, description="Target price")
    stop_loss: Optional[float] = Field(None, description="Stop loss price")
    
    # Scoring and analysis
    overall_score: float = Field(..., description="Overall recommendation score")
    confidence_score: float = Field(..., description="Confidence in recommendation")
    risk_score: float = Field(..., description="Risk assessment score")
    momentum_score: Optional[float] = Field(None, description="Momentum analysis score")
    fundamental_score: Optional[float] = Field(None, description="Fundamental analysis score")
    technical_score: Optional[float] = Field(None, description="Technical analysis score")
    
    # Recommendation details
    recommendation_action: RecommendationAction = Field(..., description="Recommended action")
    recommendation_strength: str = Field(..., description="Strength of recommendation")
    upside_potential: Optional[float] = Field(None, description="Expected upside percentage")
    downside_risk: Optional[float] = Field(None, description="Potential downside percentage")
    risk_reward_ratio: Optional[float] = Field(None, description="Risk to reward ratio")
    
    # Market data
    volume: Optional[int] = Field(None, description="Trading volume")
    volume_ratio: Optional[float] = Field(None, description="Volume compared to average")
    per_change: Optional[float] = Field(None, description="Percentage change")
    market_cap: Optional[float] = Field(None, description="Market capitalization")
    
    # Strategy-specific flags
    momentum: bool = Field(default=False, description="Momentum strategy flag")
    breakout: bool = Field(default=False, description="Breakout strategy flag")
    reversal: bool = Field(default=False, description="Reversal strategy flag")
    sector_rotation: bool = Field(default=False, description="Sector rotation flag")
    fundamental: bool = Field(default=False, description="Fundamental analysis flag")
    value: bool = Field(default=False, description="Value investing flag")
    quality: bool = Field(default=False, description="Quality investing flag")
    
    # Additional analysis
    categories: List[str] = Field(default_factory=list, description="Analysis categories")
    indicators: Dict[str, Any] = Field(default_factory=dict, description="Technical indicators")
    fundamental_metrics: Dict[str, Any] = Field(default_factory=dict, description="Fundamental metrics")
    
    # Tracking information
    appearances: int = Field(default=1, description="Number of times recommended")
    category_count: int = Field(default=0, description="Number of categories matched")
    recommendation_rank: int = Field(..., description="Rank in recommendation list")
    
    # Performance tracking (for follow-up analysis)
    performance_1d: Optional[float] = Field(None, description="1-day performance after recommendation")
    performance_1w: Optional[float] = Field(None, description="1-week performance after recommendation")
    performance_1m: Optional[float] = Field(None, description="1-month performance after recommendation")
    performance_3m: Optional[float] = Field(None, description="3-month performance after recommendation")
    max_gain: Optional[float] = Field(None, description="Maximum gain achieved")
    max_loss: Optional[float] = Field(None, description="Maximum loss encountered")
    
    # Outcome tracking
    target_achieved: Optional[bool] = Field(None, description="Whether target price was achieved")
    stop_loss_hit: Optional[bool] = Field(None, description="Whether stop loss was triggered")
    outcome_date: Optional[datetime] = Field(None, description="Date of outcome determination")
    outcome_notes: Optional[str] = Field(None, description="Notes about recommendation outcome")

class HistoricalRecommendationBatch(BaseModel):
    """Complete batch of historical recommendations from a single cron execution."""
    
    # Batch identification
    batch_id: str = Field(default_factory=lambda: str(uuid.uuid4()), description="Unique batch ID")
    execution_id: str = Field(..., description="Cron execution ID")
    cron_job_id: str = Field(..., description="Cron job identifier")
    
    # Strategy and timing
    strategy: RecommendationStrategy = Field(..., description="Trading strategy used")
    source: RecommendationSource = Field(..., description="Source of recommendations")
    generated_at: datetime = Field(default_factory=datetime.now, description="Generation timestamp")
    
    # Market context
    market_condition: str = Field(..., description="Market condition during generation")
    trading_session: str = Field(..., description="Trading session identifier")
    market_open: bool = Field(..., description="Whether market was open")
    
    # Request parameters
    request_parameters: Dict[str, Any] = Field(default_factory=dict, description="Request parameters used")
    limit_requested: int = Field(..., description="Number of recommendations requested")
    min_score_threshold: float = Field(..., description="Minimum score threshold applied")
    
    # Recommendations
    recommendations: List[HistoricalStockRecommendation] = Field(..., description="List of stock recommendations")
    total_recommendations: int = Field(..., description="Total number of recommendations generated")
    
    # Analysis metadata
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Generation metadata")
    algorithm_info: Dict[str, Any] = Field(default_factory=dict, description="Algorithm information")
    performance_metrics: Dict[str, Any] = Field(default_factory=dict, description="Generation performance metrics")
    
    # Data quality
    data_quality_score: float = Field(default=100.0, description="Data quality assessment score")
    validation_errors: List[str] = Field(default_factory=list, description="Validation errors encountered")
    warnings: List[str] = Field(default_factory=list, description="Generation warnings")
    
    # Storage metadata
    stored_at: datetime = Field(default_factory=datetime.now, description="Storage timestamp")
    schema_version: str = Field(default="1.0", description="Schema version")

class RecommendationPerformanceTracker(BaseModel):
    """Tracks performance of historical recommendations over time."""
    
    recommendation_id: str = Field(..., description="Reference to historical recommendation")
    symbol: str = Field(..., description="Stock symbol")
    batch_id: str = Field(..., description="Batch ID")
    strategy: RecommendationStrategy = Field(..., description="Strategy used")
    
    # Original recommendation details
    recommended_at: datetime = Field(..., description="Recommendation timestamp")
    recommended_price: float = Field(..., description="Price at recommendation")
    target_price: Optional[float] = Field(None, description="Target price")
    stop_loss: Optional[float] = Field(None, description="Stop loss price")
    recommendation_action: RecommendationAction = Field(..., description="Recommended action")
    
    # Performance tracking
    tracking_periods: Dict[str, float] = Field(default_factory=dict, description="Performance at different periods")
    current_price: Optional[float] = Field(None, description="Current stock price")
    current_return: Optional[float] = Field(None, description="Current return percentage")
    
    # Outcome determination
    status: str = Field(default="active", description="Tracking status: active, completed, stopped")
    outcome: Optional[str] = Field(None, description="Final outcome: target_hit, stop_loss, expired")
    outcome_date: Optional[datetime] = Field(None, description="Date outcome was determined")
    final_return: Optional[float] = Field(None, description="Final return percentage")
    
    # Analysis
    volatility: Optional[float] = Field(None, description="Price volatility during tracking")
    max_favorable_excursion: Optional[float] = Field(None, description="Best performance achieved")
    max_adverse_excursion: Optional[float] = Field(None, description="Worst performance experienced")
    
    # Tracking metadata
    last_updated: datetime = Field(default_factory=datetime.now, description="Last update timestamp")
    update_count: int = Field(default=0, description="Number of updates performed")

class RecommendationHistoryStorage:
    """Database manager for historical recommendation storage and analysis."""
    
    def __init__(self, use_mongodb: bool = True, mongodb_url: str = "mongodb://localhost:27017", db_name: str = "trading_history"):
        self.use_mongodb = use_mongodb
        self.db_name = db_name
        
        if use_mongodb:
            self.client = motor.motor_asyncio.AsyncIOMotorClient(mongodb_url)
            self.db = self.client[db_name]
            self.batches_collection = self.db.recommendation_batches
            self.recommendations_collection = self.db.individual_recommendations
            self.performance_collection = self.db.recommendation_performance
            self.analytics_collection = self.db.recommendation_analytics
        else:
            # Fallback to file-based storage
            self.storage_dir = Path("api/recommendation_history")
            self.storage_dir.mkdir(exist_ok=True)
    
    async def initialize(self):
        """Initialize the historical storage system and create indexes."""
        try:
            if self.use_mongodb:
                # Test connection
                await self.client.admin.command('ping')
                
                # Create indexes for efficient querying
                # Batch collection indexes
                await self.batches_collection.create_index([
                    ("strategy", ASCENDING),
                    ("generated_at", DESCENDING)
                ])
                await self.batches_collection.create_index([
                    ("execution_id", ASCENDING)
                ])
                await self.batches_collection.create_index([
                    ("market_condition", ASCENDING),
                    ("trading_session", ASCENDING)
                ])
                
                # Individual recommendations indexes
                await self.recommendations_collection.create_index([
                    ("symbol", ASCENDING),
                    ("generated_at", DESCENDING)
                ])
                await self.recommendations_collection.create_index([
                    ("strategy", ASCENDING),
                    ("recommendation_action", ASCENDING),
                    ("generated_at", DESCENDING)
                ])
                await self.recommendations_collection.create_index([
                    ("overall_score", DESCENDING),
                    ("confidence_score", DESCENDING)
                ])
                
                # Performance collection indexes
                await self.performance_collection.create_index([
                    ("symbol", ASCENDING),
                    ("recommended_at", DESCENDING)
                ])
                await self.performance_collection.create_index([
                    ("strategy", ASCENDING),
                    ("status", ASCENDING),
                    ("recommended_at", DESCENDING)
                ])
                
                logger.info("✅ Recommendation history storage initialized with MongoDB")
            else:
                logger.info("✅ Recommendation history storage initialized with file storage")
                
        except Exception as e:
            logger.warning(f"⚠️ MongoDB initialization failed, using file storage: {e}")
            self.use_mongodb = False
            self.storage_dir = Path("api/recommendation_history")
            self.storage_dir.mkdir(parents=True, exist_ok=True)

    async def close(self):
        """Close database connections."""
        try:
            if self.use_mongodb and self.client:
                self.client.close()
                logger.info("✅ Recommendation history MongoDB connection closed")
        except Exception as e:
            logger.warning(f"⚠️ Error closing recommendation history connection: {e}")

    async def store_recommendation_batch(self, 
                                         execution_id: str,
                                         cron_job_id: str,
                                         strategy: RecommendationStrategy,
                                         recommendations: List[Dict[str, Any]],
                                         metadata: Dict[str, Any],
                                         request_parameters: Dict[str, Any],
                                         market_context: Dict[str, Any]) -> str:
        """Store a complete batch of recommendations from a cron execution."""
        
        try:
            # Convert recommendations to HistoricalStockRecommendation objects
            historical_recommendations = []
            for i, rec in enumerate(recommendations, 1):
                historical_rec = HistoricalStockRecommendation(
                    symbol=rec.get('symbol', ''),
                    name=rec.get('name', ''),
                    exchange=rec.get('exchange', 'NSE'),
                    sector=rec.get('sector'),
                    price_at_recommendation=float(rec.get('price', 0)),
                    target_price=rec.get('target_price'),
                    stop_loss=rec.get('stop_loss'),
                    overall_score=float(rec.get('score', 0)),
                    confidence_score=float(rec.get('confidence_score', rec.get('score', 0))),
                    risk_score=float(rec.get('risk_score', 50)),
                    momentum_score=rec.get('momentum_score'),
                    fundamental_score=rec.get('fundamental_score'),
                    technical_score=rec.get('technical_score'),
                    recommendation_action=self._parse_recommendation_action(rec.get('recommendation_type', 'buy')),
                    recommendation_strength=rec.get('recommendation_type', 'Buy'),
                    upside_potential=rec.get('upside_potential'),
                    downside_risk=rec.get('downside_risk'),
                    risk_reward_ratio=rec.get('risk_reward_ratio'),
                    volume=rec.get('volume'),
                    volume_ratio=rec.get('volume_ratio'),
                    per_change=rec.get('per_change'),
                    market_cap=rec.get('market_cap'),
                    momentum=rec.get('momentum', False),
                    breakout=rec.get('breakout', False),
                    reversal=rec.get('reversal', False),
                    sector_rotation=rec.get('sector_rotation', False),
                    fundamental=rec.get('fundamental', False),
                    value=rec.get('value', False),
                    quality=rec.get('quality', False),
                    categories=rec.get('categories', []),
                    indicators=rec.get('indicators', {}),
                    fundamental_metrics=rec.get('fundamental_metrics', {}),
                    appearances=rec.get('appearances', 1),
                    category_count=rec.get('category_count', 0),
                    recommendation_rank=i
                )
                historical_recommendations.append(historical_rec)
            
            # Create batch record
            batch = HistoricalRecommendationBatch(
                execution_id=execution_id,
                cron_job_id=cron_job_id,
                strategy=strategy,
                source=RecommendationSource.CRON_SCHEDULED,
                market_condition=market_context.get('market_condition', 'unknown'),
                trading_session=market_context.get('trading_session', ''),
                market_open=market_context.get('market_open', False),
                request_parameters=request_parameters,
                limit_requested=request_parameters.get('top_recommendations', len(recommendations)),
                min_score_threshold=request_parameters.get('min_score', 0),
                recommendations=historical_recommendations,
                total_recommendations=len(historical_recommendations),
                metadata=metadata,
                algorithm_info=metadata.get('algorithm_info', {}),
                performance_metrics=metadata.get('performance_metrics', {}),
                data_quality_score=self._calculate_data_quality_score(historical_recommendations)
            )
            
            if self.use_mongodb:
                # Convert to dict and handle enum serialization
                batch_doc = self._serialize_for_mongodb(batch.dict())
                batch_result = await self.batches_collection.insert_one(batch_doc)
                
                # Store individual recommendations for easier querying
                for rec in historical_recommendations:
                    rec_doc = self._serialize_for_mongodb(rec.dict())
                    rec_doc.update({
                        'batch_id': batch.batch_id,
                        'execution_id': execution_id,
                        'strategy': strategy.value,  # Convert enum to string
                        'generated_at': batch.generated_at,
                        'market_condition': batch.market_condition,
                        'trading_session': batch.trading_session
                    })
                    await self.recommendations_collection.insert_one(rec_doc)
                
                # Initialize performance tracking for each recommendation
                await self._initialize_performance_tracking(batch)
                
                logger.info(f"✅ Stored recommendation batch: {batch.batch_id} with {len(historical_recommendations)} recommendations")
                return batch.batch_id
                
            else:
                # File-based storage
                batch_file = self.storage_dir / f"batch_{batch.batch_id}.json"
                with open(batch_file, 'w') as f:
                    json.dump(batch.dict(), f, default=str, indent=2)
                
                # Store individual recommendations
                for rec in historical_recommendations:
                    rec_file = self.storage_dir / f"rec_{batch.batch_id}_{rec.symbol}.json"
                    rec_data = rec.dict()
                    rec_data.update({
                        'batch_id': batch.batch_id,
                        'execution_id': execution_id,
                        'strategy': strategy.value,
                        'generated_at': batch.generated_at.isoformat()
                    })
                    with open(rec_file, 'w') as f:
                        json.dump(rec_data, f, default=str, indent=2)
                
                return batch.batch_id
                
        except Exception as e:
            logger.error(f"❌ Failed to store recommendation batch: {e}")
            return ""

    async def get_recommendation_history(self,
                                         symbol: Optional[str] = None,
                                         strategy: Optional[RecommendationStrategy] = None,
                                         start_date: Optional[datetime] = None,
                                         end_date: Optional[datetime] = None,
                                         limit: int = 100) -> List[Dict[str, Any]]:
        """Get historical recommendation data with filtering."""
        
        try:
            if self.use_mongodb:
                # Build query
                query = {}
                if symbol:
                    query["symbol"] = symbol
                if strategy:
                    query["strategy"] = strategy.value
                if start_date or end_date:
                    date_query = {}
                    if start_date:
                        date_query["$gte"] = start_date
                    if end_date:
                        date_query["$lte"] = end_date
                    query["generated_at"] = date_query
                
                cursor = self.recommendations_collection.find(query).sort("generated_at", DESCENDING).limit(limit)
                results = []
                async for doc in cursor:
                    if "_id" in doc:
                        doc["_id"] = str(doc["_id"])
                    results.append(doc)
                
                return results
            else:
                # File-based storage
                results = []
                for file_path in self.storage_dir.glob("rec_*.json"):
                    try:
                        with open(file_path, 'r') as f:
                            data = json.load(f)
                        
                        # Apply filters
                        if symbol and data.get("symbol") != symbol:
                            continue
                        if strategy and data.get("strategy") != strategy.value:
                            continue
                        
                        results.append(data)
                    except Exception:
                        continue
                
                # Sort by generation time
                results.sort(key=lambda x: x.get("generated_at", ""), reverse=True)
                return results[:limit]
                
        except Exception as e:
            logger.error(f"❌ Failed to get recommendation history: {e}")
            return []

    async def get_batch_analytics(self,
                                  strategy: Optional[RecommendationStrategy] = None,
                                  days: int = 30) -> Dict[str, Any]:
        """Get analytics on recommendation batches."""
        
        try:
            start_date = datetime.now() - timedelta(days=days)
            
            if self.use_mongodb:
                # Build aggregation pipeline
                match_stage = {"generated_at": {"$gte": start_date}}
                if strategy:
                    match_stage["strategy"] = strategy.value
                
                pipeline = [
                    {"$match": match_stage},
                    {"$group": {
                        "_id": "$strategy",
                        "total_batches": {"$sum": 1},
                        "total_recommendations": {"$sum": "$total_recommendations"},
                        "avg_recommendations_per_batch": {"$avg": "$total_recommendations"},
                        "avg_score": {"$avg": {"$avg": "$recommendations.overall_score"}},
                        "unique_symbols": {"$addToSet": "$recommendations.symbol"}
                    }},
                    {"$addFields": {
                        "unique_symbols_count": {"$size": "$unique_symbols"}
                    }}
                ]
                
                results = {}
                async for doc in self.batches_collection.aggregate(pipeline):
                    strategy_name = doc["_id"]
                    results[strategy_name] = {
                        "total_batches": doc["total_batches"],
                        "total_recommendations": doc["total_recommendations"],
                        "avg_recommendations_per_batch": round(doc["avg_recommendations_per_batch"], 2),
                        "avg_score": round(doc["avg_score"], 2),
                        "unique_symbols_count": doc["unique_symbols_count"]
                    }
                
                return {
                    "analysis_period_days": days,
                    "strategy_analytics": results,
                    "summary": {
                        "total_strategies": len(results),
                        "total_batches": sum(r["total_batches"] for r in results.values()),
                        "total_recommendations": sum(r["total_recommendations"] for r in results.values())
                    }
                }
                
            else:
                # File-based analytics (simplified)
                batch_files = list(self.storage_dir.glob("batch_*.json"))
                total_batches = len(batch_files)
                total_recommendations = 0
                
                for batch_file in batch_files:
                    try:
                        with open(batch_file, 'r') as f:
                            data = json.load(f)
                        total_recommendations += data.get("total_recommendations", 0)
                    except Exception:
                        continue
                
                return {
                    "analysis_period_days": days,
                    "total_batches": total_batches,
                    "total_recommendations": total_recommendations,
                    "avg_recommendations_per_batch": total_recommendations / max(total_batches, 1)
                }
                
        except Exception as e:
            logger.error(f"❌ Failed to get batch analytics: {e}")
            return {"error": str(e)}

    def _parse_recommendation_action(self, action_str: str) -> RecommendationAction:
        """Parse recommendation action from string."""
        action_lower = action_str.lower().replace(" ", "_")
        
        action_mapping = {
            "strong_buy": RecommendationAction.STRONG_BUY,
            "buy": RecommendationAction.BUY,
            "moderate_buy": RecommendationAction.MODERATE_BUY,
            "hold": RecommendationAction.HOLD,
            "sell": RecommendationAction.SELL,
            "avoid": RecommendationAction.AVOID
        }
        
        return action_mapping.get(action_lower, RecommendationAction.BUY)

    def _calculate_data_quality_score(self, recommendations: List[HistoricalStockRecommendation]) -> float:
        """Calculate data quality score for recommendations."""
        if not recommendations:
            return 0.0
        
        total_score = 0
        total_checks = 0
        
        for rec in recommendations:
            checks = 0
            score = 0
            
            # Check if essential fields are present
            if rec.symbol:
                score += 1
            checks += 1
            
            if rec.price_at_recommendation > 0:
                score += 1
            checks += 1
            
            if rec.overall_score > 0:
                score += 1
            checks += 1
            
            if rec.recommendation_action:
                score += 1
            checks += 1
            
            # Additional quality checks
            if rec.target_price:
                score += 1
            checks += 1
            
            if rec.categories:
                score += 1
            checks += 1
            
            total_score += (score / checks) * 100 if checks > 0 else 0
            total_checks += 1
        
        return total_score / total_checks if total_checks > 0 else 0.0

    def _serialize_for_mongodb(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Convert enum objects to strings for MongoDB storage."""
        def convert_value(value):
            if isinstance(value, Enum):
                return value.value
            elif isinstance(value, dict):
                return {k: convert_value(v) for k, v in value.items()}
            elif isinstance(value, list):
                return [convert_value(item) for item in value]
            else:
                return value
        
        return convert_value(data)

    async def _initialize_performance_tracking(self, batch: HistoricalRecommendationBatch):
        """Initialize performance tracking for recommendations."""
        try:
            for rec in batch.recommendations:
                tracker = RecommendationPerformanceTracker(
                    recommendation_id=f"{batch.batch_id}_{rec.symbol}",
                    symbol=rec.symbol,
                    batch_id=batch.batch_id,
                    strategy=batch.strategy,
                    recommended_at=batch.generated_at,
                    recommended_price=rec.price_at_recommendation,
                    target_price=rec.target_price,
                    stop_loss=rec.stop_loss,
                    recommendation_action=rec.recommendation_action
                )
                
                if self.use_mongodb:
                    # Serialize the tracker data for MongoDB
                    tracker_doc = self._serialize_for_mongodb(tracker.dict())
                    await self.performance_collection.insert_one(tracker_doc)
                
        except Exception as e:
            logger.error(f"❌ Failed to initialize performance tracking: {e}")

# Global instance
recommendation_history_storage = RecommendationHistoryStorage() 